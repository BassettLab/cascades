\documentclass[superscriptaddress]{revtex4-1}
\usepackage{graphicx} % needed for figures
\graphicspath{ {Figures/} }
\usepackage{epstopdf}
\usepackage[caption=false]{subfig}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{bm}

\newcommand{\subscr}[2]{{#1}_{\textup{#2}}}
\newcommand{\supscr}[2]{{#1}^{\textup{#2}}}
\newcommand{\Ker}{\operatorname{Ker}}
%\newcommand{\Det}{\operatorname{Det}}
\newcommand{\Rank}{\operatorname{Rank}}
\newcommand{\Image}{\operatorname{Im}}
\newcommand{\real}{\mathbb{R}}
\newcommand{\complex}{\mathbb{C}}
%\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\mc}{\mathcal}
\newcommand{\argmax}[2] {\mathrm{arg}\max_{#1}#2}
\newcommand{\argmin}[2] {\mathrm{arg}\min_{#1}#2}


\begin{document}
\title{Reconstruction of $k$ Impulse Functions from $k$ Measurements of a Linear Dynamical System}
\date{\today}

\maketitle


\section{Mathematical Framework}
\subsection{Expected Value of Stochastic Discrete Maps}
Consider a network represented by directed graph $\mc G = (\mc V, \mc E)$, where $\mc V = {1, \dotsm, n}$, and $\mc E \subseteq \mc V \times \mc V$ are the sets of network vertices and directed edges. Let $A = [a_{ij}]$ be the weighted and directed adjacency matrix of $\mc G$. At each time point $t \in \mathbb{Z}_{\geq 0}$, we associate each node $i$ with a discrete non-negative random variable $X_i^t$.

The evolution of the dynamics in our system follow a hierarchical stochastic process. Starting at some non-random initial state $\bm{x}^0$, we define discrete non-negative random variable $X_{j}^t$ that represents the number of successful transmissions received by node $j$ at time $t$. Initially, we define
\begin{align*}
X_j^{t+1} \sim \sum_{i=1}^n B(X_i^{t},a_{ji}),
\end{align*}
which is the sum of binomial distributions conditioned on random variables that are the states at time $t$. The expectation of this conditional distribution is given by
\begin{align*}
\mathbb{E}[X_j^{t+1}] 
&= \mathbb{E}[\mathbb{E}[X_j^{t+1}|\bm{X}^t]]\\
&= \mathbb{E}[\mathbb{E}[\sum_{i=1}^n B(X_i^t,a_{ji})]]\\
&= \mathbb{E}[\sum_{i=1}^n \mathbb{E}[B(X_i^t,a_{ji})]]\\
&= \mathbb{E}[\sum_{i=1}^n a_{ji} X_i^t]\\
&= \sum_{i=1}^n a_{ji} \mathbb{E}[X_i^t]\\
&= \bm{a}_j \bm{X}^t.
\end{align*}
In vector form, this expectation becomes
\begin{align*}
\mathbb{E}[\bm{X}^{t+1}] = A\mathbb{E}[\bm{X}^t],
\end{align*}
which we see is a simple discrete linear map.


\subsection{Upper Bound on Variance}
As exciting as linearity in these stochastic linear maps are, the distributional variances provide more trouble. First, we establish a useful inequality for our purposes. If $\alpha_1, \dotsm, \alpha_n$ are real numbers such that $\alpha_i \geq 0$ where $\sum_{i=1}^n = c$, and $X_1, \dotsm, X_n$ are random variables. Then
\begin{align*}
Var \left( \sum_{i=1}^n \alpha_i X_i \right) 
&\leq \left( \sum_{i=1}^n \alpha_i \right) \sum_{i=1}^n \alpha_i Var(X_i)\\
&\leq c \sum_{i=1}^n \alpha_i Var(X_i).
\end{align*}
For hierarchical mixture models, we have the following formula
\begin{align*}
Var[X_j^{t+1}] 
&= 
\mathbb{E}\left[Var\left[X_j^{t+1}|\bm{X}^t\right]\right] +
Var\left[\mathbb{E}\left[X_j^{t+1}|\bm{X}^t\right]\right]\\
&= 
\mathbb{E}\left[\sum_{i=1}^n a_{ji} (1 - a_{ji}) X_i^t \right] +
Var\left[\sum_{i=1}^n a_{ji} X_i^t\right]\\
&=
\sum_{i=1}^n a_{ji} (1 - a_{ji}) \mathbb{E}\left[X_i^t \right] +
Var\left[\sum_{i=1}^n a_{ji} X_i^t\right]\\
&\leq
\sum_{i=1}^n a_{ji} (1 - a_{ji}) \mathbb{E}\left[X_i^t \right] +
c \sum_{i=1}^n a_{ji} Var\left[X_i^t\right],
\end{align*}
which, we see is linear in the expected value and variance of $X_i^t$, and therefore can write
\begin{align*}
Var\left[\bm{X}^{t+1}\right] \leq (A - A_2)\mathbb{E}\left[\bm{X}^t\right] + cAVar\left[\bm{X}^t\right],
\end{align*}
where $A_2$ is a matrix with entries $[a_2]_{ij} = [a]_{ij}^2$. We notice this relationship is recurrent, and can propagate all the way back to some initial condition
\begin{align*}
Var\left[\bm{X}^{t+1}\right] 
\leq 
\left( \sum_{i=0}^k c^i\left[A^{k+1} - A^i A_2 A^{k-i} \right]\right) \mathbb{E}\left[\bm{X}^0\right] + c^{k+1} A^k A_2 Var\left[\bm{X}^0\right],
\end{align*}
and when the branching parameter $c = 1$:
\begin{align*}
Var\left[\bm{X}^{t+1}\right] 
\leq 
\left( (k+1)A^{k+1} - \sum_{i=0}^k A^i A_2 A^{k-i} \right) \mathbb{E}\left[\bm{X}^0\right] +A^k A_2 Var\left[\bm{X}^0\right].
\end{align*}
Another way to represent this inequality is
\begin{align*}
Var[\bm{X}^{t+1}] \leq \left(\sum_{i=0}^k c^i A^i A^*A^{k-i}\right) \mathbb{E}[\bm{X}^0] + c^{k+1}A^kA_2Var[\bm{X}^0].
\end{align*}
Here we see that $A^* = A-A_2$ acts as a sort of dispersion matrix, where the more $A^*$ projects the eigenvector with largest eigenvalue of $A$ away from itself, the lower the variance will be. One trivial way to decrease the variance is to make the entries $[a]_{ij}$ close to 0 or 1 such that the entries of $[a(1-a)]_{ij}$ become very small. We also see that the variance of the original distribution propagates linearly with the time step, implying that for critical systems with branching parameter = 1, the variance of the original distribution does not factor into the growth of the state variance beyond a constant value. 



\subsection{Intuition of Variance Bound and Slope From 1 Eigenvector Case}
Suppose our matrix $A$ contained only a single non-zero eigenvalue $\lambda = 1$ composed of some eigenvector $\bm{v}$ such that $A = \bm{v}\bm{v}^T$. Then for $\bm{v}_2$ containing squared elements of $\bm{v}$, we have
\begin{align*}
Var[\bm{X}^{t+1}] 
&\leq \left((k+1)A^{k+1} - \sum_{i=0}^k A^iA_2A^{k-i} \right)\mathbb{E}[\bm{X}^0] + A^kA_2Var[\bm{X}^0]\\
&\leq \left((k+1)(\bm{v}\bm{v}^T)^{k+1} - \sum_{i=0}^k (\bm{v}\bm{v}^T)^i(\bm{v}_2\bm{v}_2^T)(\bm{v}\bm{v}^T)^{k-i} \right)\mathbb{E}[\bm{X}^0] + (\bm{v}\bm{v}^T)^k\bm{v}_2\bm{v}_2^TVar[\bm{X}^0]\\
&\leq \left((k+1)(\bm{v}\bm{v}^T) - (k-1)(\bm{v}\bm{v}^T)(\bm{v}_2\bm{v}_2^T)(\bm{v}\bm{v}^T) -(\bm{v}_2\bm{v}_2^T)(\bm{v}\bm{v}^T) - (\bm{v}\bm{v}^T)(\bm{v}_2\bm{v}_2^T) \right)\mathbb{E}[\bm{X}^0] + (\bm{v}\bm{v}^T)\bm{v}_2\bm{v}_2^TVar[\bm{X}^0]\\
&\leq \left((k+1)(\bm{v}\bm{v}^T) - (k-1)(\bm{v}^T\bm{v}_2)^2(\bm{v}\bm{v}^T) -(\bm{v}_2\bm{v}_2^T)(\bm{v}\bm{v}^T) - (\bm{v}\bm{v}^T)(\bm{v}_2\bm{v}_2^T) \right)\mathbb{E}[\bm{X}^0] + (\bm{v}\bm{v}^T)\bm{v}_2\bm{v}_2^TVar[\bm{X}^0]\\
&\leq \left(k(1-(\bm{v}^T\bm{v}_2)^2) + 1 + (\bm{v}^T\bm{v}_2)^2 \right)(\bm{v}\bm{v}^T)\mathbb{E}[\bm{X}^0] - (\bm{v}^T\bm{v}_2)(\bm{v}_2\bm{v}^T + \bm{v}\bm{v}_2^T) \mathbb{E}[\bm{X}^0] + (\bm{v}\bm{v}^T)\bm{v}_2\bm{v}_2^TVar[\bm{X}^0].
\end{align*}
While this expression may look very confusing, the key aspect to notice is that the only term that depends on the time step $k$ is
\begin{align*}
1-(\bm{v}^T\bm{v}_2)^2,
\end{align*}
where $\bm{v}^T\bm{v}_2$ is simply a sum of each element of $\bm{v}$ raised to the third power. Hence, the closer the entries of $\bm{v}$ are to 1, the smaller this slope will be. To maximize this slope, we just require that every element of $\bm{v}$ is equal to $\frac{1}{n}$. Hence, for the extreme case where our matrix has rank 1 with one non-zero eigenvalue and corresponding eigenvector, we see that the increase in variance over time is given by a very simple expression. 




\subsection{Exact Variance for First Step}
Suppose our initial inputs are drawn from independent distributions with mean $\mathbb{E}[\bm{X}^0]$ and variance $Var[\bm{X}^0]$. Then the firing rates immediately after have exact variance
\begin{align*}
Var[\bm{X}^1] 
&= \mathbb{E}[Var[\bm{X}^1|\bm{X}^0]] + Var[\mathbb{E}[\bm{X}^1|\bm{X}^0]]\\
&= \mathbb{E}[A^*\bm{X}^0] + Var[A\bm{X}^0]\\
&= A^*\mathbb{E}[\bm{X}^0] + A_2 Var[\bm{X}^0]\\
&= A\mathbb{E}[\bm{X}^0] + A_2 (Var[\bm{X}^0] - \mathbb{E}[\bm{X}^0])\\
&= \mathbb{E}[\bm{X}^1] + A_2 (Var[\bm{X}^0] - \mathbb{E}[\bm{X}^0]).
\end{align*}
We see that there is a linear aspect in the growth of the variance, where one component of $Var[\bm{X}^1]$ is $\mathbb{E}[\bm{X}^1]$. This term increases the variance as quickly as the mean, which is bad. Alternatively, the second term can reduce the variance of $\bm{X}^1$ if the variance of the initial distribution is lower than the expected value. Suppose very simply that there is no variance in the initial distribution. Then $Var[\bm{X}^1] = \mathbb{E}[\bm{X}^1] - A_2\mathbb{E}[\bm{X}^0]$. From this relation alone, we see that to minimize some measure of variance to expected value, we want our initial condition to excite the largest eigenmode of $A_2$, not necessarily $A$. 




\subsection{Bayes Theorem and Posteriors}
In the quest to understand the question of input reconstruction, suppose we have some initial state $\bm{X}^0$ drawn from some distribution. The question we are interested in is how to reconstruct this initial state given a measurement later on. Suppose this later measurement occurs at time $T = 1$. Then $X_j^1 \sim \sum_{i=1}^n B(X_i^0, a_{ji})$. If all inputs to the $j$th neuron are identical, then $X_j^1 \sim \sum_{i=1}^n B(X_i^0, a_j) = B(\bm{o}_j^T \bm{X}^0, a_j)$. Hence,
\begin{align*}
P(X_j^1 = x_j^1 | \bm{X}^0 = \bm{x}_0) = \begin{pmatrix} \bm{o}^T\bm{X}^0 \\ x_j^1\end{pmatrix} a_j^{x_j^1} (1-a_j)^{\bm{o}^T\bm{X}^0-x_j^1}.
\end{align*}
Via Bayes Theorem, we can invert this conditional probability
\begin{align*}
P(\bm{X}^0 = \bm{x}^0 | X_j^1 = x_j^1) = \frac{P(X_j^1 = x_j^1 | \bm{X}^0 = \bm{x}_0) P(\bm{X}^0 = \bm{x}^0)}{P(X_j^1 = x_j^1)}.
\end{align*}
We note that because what we measure is $X_j^1$, across all guesses of initial state, $P(X_j^1 = x_j^1)$ remains constant. We also note that if the initial states are drawn independently of each other, $P(\bm{X}^0 = \bm{x}^0) = \prod_{i = 1}^n P(X_i^0 = x_i^0)$. Hence, we can write
\begin{align*}
P(\bm{X}^0 = \bm{x}^0 | X_j^1 = x_j^1) \propto \begin{pmatrix} \bm{o}^T\bm{X}^0 \\ x_j^1\end{pmatrix} a_j^{x_j^1} (1-a_j)^{\bm{o}^T\bm{X}^0-x_j^1} \prod_{i = 1}^n P(X_i^0 = x_i^0),
\end{align*}
which we can write as the log-likelihood
\begin{align*}
\log\left(P(\bm{X}^0 = \bm{x}^0 | X_j^1 = x_j^1)\right) 
\propto \log\left(\begin{pmatrix} \bm{o}^T\bm{x}^0 \\ x_j^1\end{pmatrix}\right) + \log\left(a_j^{x_j^1} (1-a_j)^{\bm{o}^T\bm{X}^0-x_j^1}\right) + \log\left(\prod_{i = 1}^n P(X_i^0 = x_i^0)\right)\\
\propto \log\left(\begin{pmatrix} \bm{o}^T\bm{x}^0 \\ x_j^1\end{pmatrix}\right) + x_j^1\log\left(a_j\right) + (\bm{o}^T\bm{x}^0-x_j^1)\log\left(1-a_j\right) + \sum_{i=1}^n \log\left(P(X_i^0 = x_i^0)\right)\\
\propto \log\left(\begin{pmatrix} \bm{o}^T\bm{x}^0 \\ x_j^1\end{pmatrix}\right) + x_j^1\log\left(\frac{a_j}{1-a_j}\right) + \bm{o}^T\bm{x}^0\log\left(1-a_j\right) + \sum_{i=1}^n \log\left(P(X_i^0 = x_i^0)\right),
\end{align*}
which in theory we can use to find the most likely initial condition given what we know about the stimulus distribution and measured data by setting $\nabla_{\bm{x}^0} \log(P(\bm{X}^0 = \bm{x}^0 | X_j^1 = x_j^1)) = \bm{0}$. 




\subsection{State-Space and Statistical Mechanics}
The next approach is to use statistical mechanics to enumerate the tree of probabilities for transitioning from one state to another. Consider a vector $\bm{X}^t$ of $n$ random variables at time $t$, drawn from $X_j^{k+1} \sim \sum_{i=1}^n B(X_i^k, a_{ji})$. Because the state transition process does not depend on system memory, the probability of transitioning from any state $\bm{x}_m$ to any other state $\bm{x}_p$ is completely governed by a non-hierarchical sum of binomial distributions. Hence, we can enumerate all possible discrete states $\bm{x}_i$, as
\begin{align*}
\bm{x}_i \in 
\left( 
\begin{bmatrix}
0 \\ 0 \\ \vdots \\ 0
\end{bmatrix},
\begin{bmatrix}
0 \\ 0 \\ \vdots \\ 1
\end{bmatrix},
\dotsm,
\begin{bmatrix}
1 \\ 1 \\ \vdots \\ 1
\end{bmatrix},
\dotsm,
\begin{bmatrix}
d \\ d \\ \vdots \\ d
\end{bmatrix}
\right),
\end{align*}
and the probability of transitioning from any state $\bm{x}_m$ and $\bm{x}_p$ is given simply as the product of sums of binomial distributions. From this system, we can construct infinite-dimensional Markov system
\begin{align*}
\bm{p}(k) = \mathbb{T}\bm{p}(k-1),
\end{align*}
where $A \rightarrow \mathbb{T}$ is a map determined by the binomial evolution, and $\mathbb{T} = PDP^{-1}$. From $\bm{p}(0)$, we can decompose
\begin{align*}
\bm{p}(0) = \bm{e}_1 + c_2\bm{e}_2 + c_3\bm{e}_3 + \dotsm = P\bm{c},
\end{align*}
to yield
\begin{align*}
\bm{p}(t) = \bm{e}_1 + c_2\lambda_2^t\bm{e}_2 + c_3\lambda_3^t\bm{e}_3 + \dotsm = PD^tP^{-1}\bm{p}(0),
\end{align*}
where avalanche durations are given simply by the first entry of $\bm{p}(t)$. We find coefficients
\begin{align*}
\bm{c} = P^{-1}\bm{p}(0). 
\end{align*}



	
\end{document}
