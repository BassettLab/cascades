\documentclass{article}

\usepackage{amsthm,amsmath,amssymb}

\begin{document}

\title{Proof}
\author{Harang Ju}

%\maketitle

\newtheorem{linear approx}{Lemma}

\begin{linear approx}
Linear approximation of spiking nodes
\[
X_j(t) = E[Y_j(t)]
\]
where $j$ is the $j^{th}$ neuron
\end{linear approx}

\begin{proof}[Proof by induction]
Let $t, k \in \mathbb{Z}$. Given $X_j(1) = 1 $ or $0$.

Show for $k=1$.\\
\indent \indent If $X_j(1) = 1$, then $Y_j(1) = 1$ and $E[Y_j(1)] = 1 = X_j(1)$. \\
\indent \indent If $X_j(1) = 0$, then $Y_j(1) = 0$ and $E[Y_j(1)] = 0 = X_j(1)$.

Show that $k \rightarrow k+1$.
Assume $X_j(k) = E[Y_j(k)]$
\begin{align*}
    X_j(k+1) &= E[Y_j(k+1)] \\
    &= E[\sum_{i\rightarrow j} \sum_{Y_i(k)} R(A_{ij})] &&\text{By definition,} \\
    &= \sum_{i\rightarrow j} E[\sum_{Y_i(k)} R(A_{ij})] \\
    &= \sum_{i\rightarrow j} E[Y_i(k)]A_{ij} &&\text{Bernoulli process, R} \\
    &= \sum_{i\rightarrow j} X_j(k)A_{ij} &&\text{Assumption} \\
    &= X_j(k+1) &&\qedhere
\end{align*}
\end{proof}
\end{document}